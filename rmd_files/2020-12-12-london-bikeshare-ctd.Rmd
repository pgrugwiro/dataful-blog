---
title: 'ADFS: London Bike Share Cntd'
author: "Phil G Rugwiro"
date: "12/11/2020"
always_allow_html: TRUE
output:
  md_document:
    variant: gfm
    preserve_yaml: TRUE

---

```{r setup, include=FALSE}
source(here::here("rmd_config.R"))
knitr::opts_chunk$set(echo = TRUE)
```



```{r echo= FALSE, message=FALSE, warning=FALSE}
# Installing and loading libraries that will be used in this analysis

packages = c("kableExtra","lubridate", "gridExtra", "tree", "tidyverse", "here", "caret")

# Load the package or install and load it
package.check <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  }
)


```


### Intro and data

In the previous post, we were able to uncover useful insights from the London Bike Sharing programme. We learned that in 2018 there were 10.3 million rentals amounting to a total of 3.5 million hours of bike rental time. We also learned that each bike on average is rented 2 times per day and each ride on averages lasts about 20 minutes. We identified the top ten most frequented bike stations as well as the most popular months for rentals. 

This post picks up from the previous by looking at the hourly weather conditions in the city of London in 2018 and attempting to analyse their impact on the number of bikes rented. Historical weather data for the city of London was retrieved from https://freemeteo.co.uk/weather. 

Preview of the weather data:

```{r echo=FALSE}
raw_weather <- read.csv('~/london_cycling/Scraping and Cleaning/london_weather.csv')
tail(raw_weather) %>%
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial") %>%
  kable_styling(latex_options = "scale_down")
```

The dataframe structure and variable data types as extracted from the webpage: 

```{r}
str(raw_weather)
```

The data must undergo a cleaning and transformation process before carrying out the analysis. The steps following steps are taken to prepare the data:

- Extracting numerical values from temperatures, wind speed, humidity and pressure,
- Filtering data to keep weather data for each hour mark instead of 30-min intervals,
- Combining the time and date columns to create a new 'datetime' column. 


Preview of the cleaned data:

```{r echo=FALSE}
clean_weather <- read.csv('~/london_cycling/Scraping and Cleaning/london_weather_clean.csv')
tail(clean_weather) %>%
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial") %>%
  kable_styling(latex_options = "scale_down")
```


Recalling from the previous post, each rental record contained timestamps for bike pick-up and drop-off down to the minute mark. This data can be aggregated to count the number of rentals in hourly intervals in 2018. 

```{r echo=FALSE}

bike_rentals <- read.csv('~/london_cycling/Scraping and Cleaning/agg_200.csv')
head(bike_rentals) %>%
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial") %>%
  kable_styling(latex_options = "scale_down")

```

Hourly weather data and hourly bike rental counts are joined to form a larger dataset containing both the weather and rental numbers. For simplicity, only 25% (200) top docking stations responsible for over half of total rentals are considered. 

Joint Data Preview:

```{r echo=FALSE}
joint_df <- read.csv('~/london_cycling/Scraping and Cleaning/joint_df.csv')
#change the time from character to datetime 
joint_df$Time <- ymd_hms(joint_df$Time)

head(joint_df) %>%
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial") %>%
  kable_styling(latex_options = "scale_down")

```


Below is the final structure of the complete dataset: 

```{r echo=FALSE}
str(joint_df)
```

### Exploratory data analysis

The first step in our exploratory data analysis is to look at the distribution of hourly bike rentals in 2018, which is our response variable of interest. 

```{r echo= FALSE}
joint_df %>% 
  ggplot(aes(Rentals.Num))+
  geom_histogram(fill = 'brown4', alpha = .666, bins = 50) +
  ggtitle('Distribution of Hourly Bike Rentals') +
  xlab("Hourly Bike Rentals") +
  ylab("Count of Hours")+
  theme(plot.title = element_text(size = 10), axis.title = element_text(size = 8))
```
The number of hourly bike rentals clearly does not follow a normal distribution. This is a fact to consider in the data modeling process. 

#### Correlations

The objective of this exercise is to estimate the number of bike rentals based on weather parameters, and weather parameters only. 

It is helpful to look at the possible correlations that exist between the variables in the dataset, which might help to reduce the number of variables and to choose the right modeling approach (Note that a strong linear correlation exists between temperature, relative temperature, and dew point, therefore only the temperature variable will be kept).

```{r echo=FALSE}

#Define a function to calculate correlations:

panel.cor <- function(x, y, ...) {
  par(usr = c(0, 1, 0, 1))
  txt <- as.character(format(cor(x, y), digits=2))
  text(0.5, 0.5, txt, cex = 3* abs(cor(x, y)))
}

#Remove non-numeric and correlated variables and make a pairs plot:

joint_df %>%
  select(-Time, -Description, -Relative.Temperature, -Dew.Point) %>%
  pairs(upper.panel = panel.cor)

```

From the graph above, a measurable (not strong) correlation is observed between the number of rentals and the temperature & relative humidity values.

The tree model below also indicates that relative humidity is a strong factor in the dataset that affects the number of bike rentals. It is also clear that no complex interactions exist between the variables in the dataset. 

```{r echo=FALSE}
#Generate a tree for the target variable:
tree_mod <- tree(Rentals.Num ~ Temperature + Relative.Temperature + Wind + 
                   Rel..humidity + Dew.Point + Pressure, data = joint_df)
plot(tree_mod)
text(tree_mod)
```

### Prediction Models

Data preparation and cleaning are generally the hardest part of most data science projects. Making predictions based on the data is largely about picking the right predictive algorithm for the dataset. The following section explores a few well known algorithms: linear model, k nearest neighbors, decision trees, and random forests models. 

The dataset is split 75% and 25% for training dataset and testing dataset respectively (we train on 3/4 of the data, and validate the model on the remaining 1/4). 


```{r warning=FALSE, message=FALSE}

#Spliting the dataset into training and testing sets:

set.seed(1, sample.kind = "Rounding")  #setting seed

test_index <- createDataPartition(y = joint_df$Temperature, 
                                  times = 1, p = 0.25, list = FALSE)

#Training and Testing sets:
train_set <- joint_df %>% slice(-test_index)
test_set <- joint_df %>% slice(test_index)

```


#### 1. Fitting a Linear Model

Recall that the rentals distribution in the dataset does not follow a normal distribution. Additionally, the number of rentals should be considered as 'count data' rather than a regular numerical continuous variable. GLM with poisson would be an appropriate method to handle this data. 

```{r}
#####
#Linear Model:
fit_lm <- glm(Rentals.Num ~ Temperature + Wind + 
                   Rel..humidity + Pressure, quasipoisson,
                 data = train_set)
summary(fit_lm)
```

The residual deviance in the model is incredibly large in comparison to the degrees of freedom. This is an indication of strong overdispersion, i.e. unexplained variations and a *clear evidence that the weather parameters do not really affect the number of bikes rented* in the dataset. 


*Testing the Linear Model*

It has just been established that there are a lot of variations in the number of bikes rented that are not explained by the weather parameters. _It would be a bad practice to rely on the weather parameters to estimate the rentals_. 

We can still attempt to make predictions in the test set using the model and see how well the model does compared to real data. 

```{r}
#predict number of bikes rented in the test set:
predict_lm <- predict(fit_lm, test_set)

```

Compare the predicted values by the linear model to the real values by calculating the RMSE. 

```{r echo=F}

models_predictions <- data_frame(
  Method="Linear Model", RMSE = sqrt(sum(
    (test_set$Rentals.Num - predict_lm)^2)/length(test_set$Time)))

models_predictions %>%  
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial")


```

On overage, the predicted numbers of bike rentals are off by a whooping 784 in comparison to the actual numbers. 

Let's see how other algorithms compare (note. the number of rentals is modeled as a continuous numerical variable in the algorithms below): 

#### 2. Fitting the kNN model:

The k-NN (k-nearest neighbors) performs the training for a given datapoint using the points that are most similar to it (neighbors). 


Fitting k-NN with default tuning parameters:
```{r}

fit_knn <- train(Rentals.Num ~ Temperature + Wind + 
                   Rel..humidity + Pressure, method = 'knn',
                 data = train_set)
```


Predicting the number of rentals in the test set:
```{r}
predict_knn <- predict(fit_knn, test_set)
```


Comparing predictions by the k-NN model to actual numbers by calculating the RMSE:
```{r echo=F, message=F, warning=F}

models_predictions <- bind_rows(models_predictions,  data_frame(
  Method="KNN Model", RMSE = sqrt(sum(
    (test_set$Rentals.Num - predict_knn)^2)/length(test_set$Time))))

models_predictions %>% 
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial")

```

The k-NN model, although it presents an improvement over the linear model, is still off by a lot!

#### 3. Fitting the Decision Trees Model

Decision trees (regression trees in our example) is another simple and popular machine learning algorithm that is used to predict outcomes based on a number of features. 

Fitting decision trees model:
```{r}
#Decision Trees:
fit_rpart <- train(Rentals.Num ~ Temperature + Wind + 
                   Rel..humidity + Pressure, method = 'rpart',
                   tuneGrid = data.frame(cp = 0.001),
                   data = train_set)

```


Predicting with decision trees model:
```{r}
predict_rpart <- predict(fit_rpart, test_set)
```


Comparing the predicted values by the decision (regression) trees model to the real values by calculating the RMSE:
```{r echo=F, message=F, warning=F}

models_predictions <- bind_rows(models_predictions,  data_frame(
  Method="Trees Model", RMSE = sqrt(sum(
    (test_set$Rentals.Num - predict_rpart)^2)/length(test_set$Time))))

models_predictions %>%
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial")

```

Another slight improvement is observed by using the decision (regression) trees algorithm. However, the numbers are still not satisfactory (which is expected). 


#### 4. Random Forests

Finally, let's consider the performance of the random forests algorithm compared to the previous three. The algorithm essentially operates by grouping a number of decision trees picked from random sampling of the data in the training set. Random forests generally tend to be more accurate than simple decision trees. 

Fitting random forests model to the training set:
```{r}
#Random Forests:
fit_rf <- train(Rentals.Num ~ Temperature + Wind + 
                     Rel..humidity + Pressure, method = 'rf',
                   data = train_set)

```


Predicting with the random forest model on the testing set:
```{r}
predict_rf <- predict(fit_rf, test_set)
```


Comparing predictions by random forest to actual values:
```{r echo=F, message=F, warning=F}

models_predictions <- bind_rows(models_predictions,  data_frame(
  Method="Forests Model", RMSE = sqrt(sum(
    (test_set$Rentals.Num - predict_rf)^2)/length(test_set$Time))))

models_predictions %>%  
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial")

```

The best model in the four studied so far is off by 453 rentals on average. This number is high compared to the nature of the dataset.

At this point, it would be appropriate to surrender and declare that we cannot predict the number of bikes that shall be rented solely based on the weather forecast. 

Before we do that, there's one final element to consider: since we're attempting to predict hourly bike rentals, let's look at the total number of bikes rented in 2018 by 'hour of the day'. 


```{r}
joint_df %>%
  mutate(hour = hour(Time)) %>%
  group_by(hour) %>%
  summarize(Hour_tot = sum(Rentals.Num)) %>%
  ggplot(aes(hour, Hour_tot)) +
  geom_line(col = 'brown4', size = 1) +
  scale_x_discrete(limits = seq(0,23,1)) +
  xlab('Hour of the Day') +
  ylab('Total bikes rented 2018') +
  ggtitle('Number of Rentals by Hour of the Day') +
  theme(plot.title = element_text(size = 10), axis.title = element_text(size = 8))

```

Looking at the data by hour of the day, one major observation is made: The spike in bike rentals at 8AM and 9AM, followed by another spike at 5PM and 6PM cannot be missed. Another secondary observation is a relatively flat usage in the hours of the night from midnight to 6AM. 
These observations lead us to make a strong assumption: *The bike usage at 8, 9, 17, & 18 hours is largely driven by the people commuting to and from work*. In this case, regardless of the weather conditions, these customers will rent the bike. This could explain a big part of variations observed in our model above. Similarly, people using the bikes in night hours perhaps do it because they don't have other alternatives and weather conditions don't matter. 
Therefore, we can attempt to make a distinction between people that use the bikes for business (e.g. going to and from work) and those that use it for pleasure. 

It would certainly make sense that the weather conditions would affect the leisure users more than it would the utility users. 

Let's re-rerun the model and recalculate the RMSEs only on the leisure users (selected hours: 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20 and 21)

```{r}
#New dataset for leisure users:

leisure_hours <- c(6,7,10,11,12,13,14,15,16,19,20,21)

leisure_df <- joint_df %>%
  mutate(Hour = hour(Time)) %>%
  filter(Hour %in% leisure_hours)
```

```{r echo= FALSE}
leisure_df %>% 
  ggplot(aes(Rentals.Num))+
  geom_histogram(fill = 'brown4', alpha = .666, bins = 50) +
  ggtitle('Distribution of Hourly Bike Rentals - Leisure Users') +
  xlab("Hourly Bike Rentals") +
  ylab("Count of Hours")+
  theme(plot.title = element_text(size = 10), axis.title = element_text(size = 8))
```

The new distribution is slightly more "normal" but not quite. GLM with poisson errors will still be the preferred approach when fitting a linear model. 

```{r include=F, message=F, echo=F}
#Spliting the dataset into training and testing sets:

set.seed(1, sample.kind = "Rounding")  #setting seed

test_index2<- createDataPartition(y = leisure_df$Temperature, 
                                  times = 1, p = 0.25, list = FALSE)

#Training and Testing sets:
train_set2 <- leisure_df %>% slice(-test_index2)
test_set2 <- leisure_df %>% slice(test_index2)



#########################################################
#Linear Model:
fit_lm2 <- glm(Rentals.Num ~ Temperature + Wind + 
                   Rel..humidity + Pressure, poisson,
                 data = train_set2)

#predict number of bikes rented in the test set:
predict_lm2 <- predict(fit_lm2, test_set2)

#compare with actual data
RMSE_Leisure_lm = sqrt(sum(
    (test_set2$Rentals.Num - predict_lm2)^2)/length(test_set2$Time))

##########################################################

#Fit knn with 20 nearest neighbors:
fit_knn2 <- train(Rentals.Num ~ Temperature + Wind + 
                   Rel..humidity + Pressure, method = 'knn',
                 tuneGrid = data.frame(k = 20),
                 data = train_set2)
#predict number of bikes rented in the test set:
predict_knn2 <- predict(fit_knn2, test_set2)

#compare with actual data:
RMSE_Leisure_knn = sqrt(sum(
    (test_set2$Rentals.Num - predict_knn2)^2)/length(test_set2$Time))

##########################################################

#Decision Trees:
fit_rpart2 <- train(Rentals.Num ~ Temperature + Wind + 
                   Rel..humidity + Pressure, method = 'rpart',
                   tuneGrid = data.frame(cp = 0.001),
                   data = train_set2)
#predict number of bikes rented in the test set:
predict_rpart2 <- predict(fit_rpart2, test_set2)

#compare with actual data:
RMSE_Leisure_rpart = sqrt(sum(
    (test_set2$Rentals.Num - predict_rpart2)^2)/length(test_set2$Time))


##########################################################


#Random Forests:
fit_rf2 <- train(Rentals.Num ~ Temperature + Wind + 
                     Rel..humidity + Pressure, method = 'rf',
                   data = train_set2)
#predict number of bikes rented in the test set:
predict_rf2 <- predict(fit_rf2, test_set2)

#compare with actual data:
RMSE_Leisure_rf = sqrt(sum(
    (test_set2$Rentals.Num - predict_rf2)^2)/length(test_set2$Time))

```


Below is a summary of the RMSE comparisons for all four models and for overall data vs. 'leisure' users. 


```{r echo=F}
models_predictions <- models_predictions %>%
  mutate(RMSE_Leisure = c(RMSE_Leisure_lm, RMSE_Leisure_knn, RMSE_Leisure_rpart, RMSE_Leisure_rf))

models_predictions %>% 
  kbl() %>%
  kable_classic_2(full_width = F, html_font = "Arial")

```
Significant improvements in our prediction power can be observed, however we can still conclude that there exist additional variations in the response variable (number of rentals) that are not explained by the weather parameters. A few additional weather parameters that were not considered that may play a key role are 'precipitation' and 'cloud description'. 
One might be curious to visualize the predicted vs. actual numbers graphically:

```{r echo=F}
actual_predicted <- data_frame(actual = test_set2$Rentals.Num, predicted = predict_rf2)

actual_predicted %>%
ggplot(aes(actual , predicted), actual_predicted) +
  geom_point() +
  geom_smooth(method = 'lm', col = 'brown4') +
  geom_text(x = 200, y = 1400, label = 
              format(cor(actual_predicted$actual, 
                         actual_predicted$predicted), digits = 3)) +
  geom_text(x = 150, y = 1500, label = 'Corr =')
```

While our best model is not great, it is not terribly bad either and the correlation coefficient of 0.7 between the actual numbers and the predicted numbers is quite impressive given the data.

It is also well possible that one can forecast the number of bike rentals for the next day based on the number of rentals observed on the prior day and achieve a better accuracy than our weather-based models. 
Nevertheless, this was an interesting exercise on the application of predictive models on a real world business dataset joined with a natural phenomenon such as weather. 
You can find the Rmd file for this post here. 
I certainly enjoyed scraping, cleaning, and analyzing this data. I hope you enjoyed reading this summary report. 
Write me! 



